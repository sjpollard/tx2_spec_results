Cray clang version 11.0.4  (bc9473a12d1f2f43cde01f962a11240263bd8908)
Target: aarch64-unknown-linux-gnu
Thread model: posix
InstalledDir: /opt/cray/pe/cce/11.0.4/cce-clang/aarch64/share/../bin
SPEC HPC(r) 2021 Benchmark Suites
Copyright 1995-2021 Standard Performance Evaluation Corporation (SPEC)

runhpc v.unknown
Using 'linux-aarch64' tools
Reading file manifests... read 14938 entries from 2 files in 0.30s (49130 files/s)
Loading runhpc modules.................
Locating benchmarks...found 31 benchmarks in 5 benchsets.
Reading config file '/home/br-spollard/SPEChpc/config/hpe_cpe.cfg'
Reading included config file '/home/br-spollard/SPEChpc/config/SUT.inc'
WARNING: Duplicate setting for "node_compute_sw_os000" on line 46
         of /home/br-spollard/SPEChpc/config/hpe_cpe.cfg
WARNING: Duplicate setting for "node_compute_sw_os001" on line 47
         of /home/br-spollard/SPEChpc/config/hpe_cpe.cfg

WARNING: OMP_NUM_THREADS is set to '64' in the run environment.  This
         value will not be used; the tools set a value for this for each
         benchmark run based on the run mode (rate or speed) and the setting
         for number of threads.
         See https://www.spec.org/hpc2021/Docs/config.html#threads
         and https://www.spec.org/hpc2021/Docs/runhpc.html#threads
Retrieving flags file (/home/br-spollard/SPEChpc/config/flags/Example_hpe_cpe_flags.xml)...


1 configuration selected:

 Action    Run Mode   Workload     Report Type     Benchmarks
--------   --------   --------   ---------------   ----------------------------
validate   speed      test       SPEChpc2021_tny   tiny                        
-------------------------------------------------------------------------------

Benchmarks selected: 505.lbm_t, 513.soma_t, 518.tealeaf_t, 519.clvleaf_t, 521.miniswp_t, 528.pot3d_t, 532.sph_exa_t, 534.hpgmgfv_t, 535.weather_t
Compiling Binaries
  Up to date 505.lbm_t base cce_mpi
  Up to date 513.soma_t base cce_mpi
  Up to date 518.tealeaf_t base cce_mpi
  Up to date 519.clvleaf_t base cce_mpi
  Up to date 521.miniswp_t base cce_mpi
  Up to date 528.pot3d_t base cce_mpi
  Up to date 532.sph_exa_t base cce_mpi
  Up to date 534.hpgmgfv_t base cce_mpi
  Up to date 535.weather_t base cce_mpi


Setting Up Run Directories
  Setting up 505.lbm_t test base cce_mpi: run_base_test_cce_mpi.0002
  Setting up 513.soma_t test base cce_mpi: run_base_test_cce_mpi.0002
  Setting up 518.tealeaf_t test base cce_mpi: run_base_test_cce_mpi.0002
  Setting up 519.clvleaf_t test base cce_mpi: run_base_test_cce_mpi.0002
  Setting up 521.miniswp_t test base cce_mpi: run_base_test_cce_mpi.0002
  Setting up 528.pot3d_t test base cce_mpi: run_base_test_cce_mpi.0002
  Setting up 532.sph_exa_t test base cce_mpi: run_base_test_cce_mpi.0002
  Setting up 534.hpgmgfv_t test base cce_mpi: run_base_test_cce_mpi.0002
  Setting up 535.weather_t test base cce_mpi: run_base_test_cce_mpi.0002
Running Benchmarks
  Running 505.lbm_t test base cce_mpi [2022-06-29 11:57:34]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/505.lbm_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/505.lbm_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
  Running 513.soma_t test base cce_mpi [2022-06-29 11:57:45]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/513.soma_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/513.soma_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
  Running 518.tealeaf_t test base cce_mpi [2022-06-29 11:57:51]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/518.tealeaf_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/518.tealeaf_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
  Running 519.clvleaf_t test base cce_mpi [2022-06-29 11:57:58]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/519.clvleaf_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/519.clvleaf_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
  Running 521.miniswp_t test base cce_mpi [2022-06-29 11:58:13]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/521.miniswp_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/521.miniswp_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
  Running 528.pot3d_t test base cce_mpi [2022-06-29 11:58:21]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/528.pot3d_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/528.pot3d_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
  Running 532.sph_exa_t test base cce_mpi [2022-06-29 11:58:29]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/532.sph_exa_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/532.sph_exa_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
  Running 534.hpgmgfv_t test base cce_mpi [2022-06-29 11:58:38]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/534.hpgmgfv_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/534.hpgmgfv_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
  Running 535.weather_t test base cce_mpi [2022-06-29 11:58:46]
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/535.weather_t/run/run_base_test_cce_mpi.0002 -f speccmds.cmd -q -e speccmds.err -o speccmds.stdout
/home/br-spollard/SPEChpc/bin/specinvoke -d /home/br-spollard/SPEChpc/benchspec/HPC/535.weather_t/run/run_base_test_cce_mpi.0002 -f compare.cmd -E -e compare.err -o compare.stdout
Success: 1x505.lbm_t 1x513.soma_t 1x518.tealeaf_t 1x519.clvleaf_t 1x521.miniswp_t 1x528.pot3d_t 1x532.sph_exa_t 1x534.hpgmgfv_t 1x535.weather_t
Producing Raw Reports
 label: cce_mpi
  workload: test
   metric: SPEChpc2021_tny_base
    format: raw -> /home/br-spollard/SPEChpc/result/hpc2021_tny.075.tiny.test.rsf
Parsing flags for 505.lbm_t base: done
Parsing flags for 513.soma_t base: done
Parsing flags for 518.tealeaf_t base: done
Parsing flags for 519.clvleaf_t base: done
Parsing flags for 521.miniswp_t base: done
Parsing flags for 528.pot3d_t base: done
Parsing flags for 532.sph_exa_t base: done
Parsing flags for 534.hpgmgfv_t base: done
Parsing flags for 535.weather_t base: done
Doing flag reduction: done
    format: Text -> /home/br-spollard/SPEChpc/result/hpc2021_tny.075.tiny.test.txt

The log for this run is in /home/br-spollard/SPEChpc/result/hpc2021.075.log

runhpc finished at 2022-06-29 11:59:21; 120 total seconds elapsed
============================= PBS epilogue =============================

End of Job Report
Run at 2022-06-29 11:59:26 for job 215176.xci00
Submitted              : 2022-06-29 11:57:17
Queued                 : 2022-06-29 11:57:17
Started                : 2022-06-29 11:57:18
Completed              : 2022-06-29 11:59:26
Queued Time            : 0:00:01 (1 second)
Elapsed Time           : 0:02:03 (123 seconds, 41% of limit)
Walltime Limit         : 0:05:00 (300 seconds)
Node Time Limit        : 0:05:00 (300 seconds)
Node Time              : 0:02:03 (123 seconds, 41% of limit)
Job Name               : jobsubmit.pbs
Queue                  : arm
Owner                  : br-spollard
Group                  : -default-
Project                : GW03
Subproject             : 
Funding                : 
Trustzone              : 
STDOUT                 : /home/br-spollard/benchmarks/testing/jobsubmit.pbs.o215176
STDERR                 : /home/br-spollard/benchmarks/testing/jobsubmit.pbs.e215176
Job Directory          : /home/br-spollard/pbs.215176.xci00.x8z
Job Arch               : XT
CPU Core Type          : arm
Total Nodes            : 1
Total Tasks            : 64
Parent Node            : xcimom
Parent Node Memory     : 
Parent Node CPU Time   : 
Compute Nodes          : 29
Electrical Groups      : 1
Run Version            : 1

For more information see https://gw4-isambard.github.io/docs/
